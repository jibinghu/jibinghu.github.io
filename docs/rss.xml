<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>ZOMBIE_</title><link>https://jibinghu.github.io</link><description>我可能当不了绝世高手</description><copyright>ZOMBIE_</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://q6.itc.cn/q_70/images01/20240415/2cdb0abd9b724802baff3b9199d3fbc4.jpeg</url><title>avatar</title><link>https://jibinghu.github.io</link></image><lastBuildDate>Thu, 14 Nov 2024 14:11:23 +0000</lastBuildDate><managingEditor>ZOMBIE_</managingEditor><ttl>60</ttl><webMaster>ZOMBIE_</webMaster><item><title>python装饰器</title><link>https://jibinghu.github.io/post/python-zhuang-shi-qi.html</link><description>在 Python 中，@ 语法通常用于 装饰器（decorator）。</description><guid isPermaLink="true">https://jibinghu.github.io/post/python-zhuang-shi-qi.html</guid><pubDate>Thu, 14 Nov 2024 14:11:00 +0000</pubDate></item><item><title>RAG/AGENT框架</title><link>https://jibinghu.github.io/post/RAG-AGENT-kuang-jia.html</link><description>在人工智能领域，**RAG（Retrieval-Augmented Generation，检索增强生成）和Agent（智能体）**框架正迅速发展。</description><guid isPermaLink="true">https://jibinghu.github.io/post/RAG-AGENT-kuang-jia.html</guid><pubDate>Thu, 14 Nov 2024 11:41:26 +0000</pubDate></item><item><title>论文学习_CODET: CODE GENERATION WITH GENERATED TESTS</title><link>https://jibinghu.github.io/post/lun-wen-xue-xi-_CODET-%20CODE%20GENERATION%20WITH%20GENERATED%20TESTS.html</link><description>&gt; GPT-4o生成：https://arxiv.org/pdf/2207.10397，给我更多关于这篇论文的要点和创新点、应用场景以及技术原理，详细&#13;
&#13;
《CodeT: Code Generation with Generated Tests》是一篇由微软研究团队于2022年7月发表的论文，旨在提升代码生成模型的性能。</description><guid isPermaLink="true">https://jibinghu.github.io/post/lun-wen-xue-xi-_CODET-%20CODE%20GENERATION%20WITH%20GENERATED%20TESTS.html</guid><pubDate>Thu, 14 Nov 2024 10:39:54 +0000</pubDate></item><item><title>NAT（网络地址转换）方式启动容器</title><link>https://jibinghu.github.io/post/NAT%EF%BC%88-wang-luo-di-zhi-zhuan-huan-%EF%BC%89-fang-shi-qi-dong-rong-qi.html</link><description>以 NAT（网络地址转换）方式启动容器，通常指的是容器通过 Docker 的默认网络模式 bridge（桥接）模式 来访问外部网络。</description><guid isPermaLink="true">https://jibinghu.github.io/post/NAT%EF%BC%88-wang-luo-di-zhi-zhuan-huan-%EF%BC%89-fang-shi-qi-dong-rong-qi.html</guid><pubDate>Wed, 13 Nov 2024 04:43:39 +0000</pubDate></item><item><title>WebSocket 学习</title><link>https://jibinghu.github.io/post/WebSocket%20-xue-xi.html</link><description># 什么是 WebSocket？&#13;
&#13;
WebSocket 是一种 **全双工通信协议**，用于在客户端（如浏览器）和服务器之间建立持久连接。</description><guid isPermaLink="true">https://jibinghu.github.io/post/WebSocket%20-xue-xi.html</guid><pubDate>Wed, 13 Nov 2024 04:36:35 +0000</pubDate></item><item><title>查看Linux系统详细版本信息</title><link>https://jibinghu.github.io/post/cha-kan-Linux-xi-tong-xiang-xi-ban-ben-xin-xi.html</link><description>`cat /etc/os-release`&#13;
&#13;
``` bash&#13;
PRETTY_NAME='Ubuntu 22.04.4 LTS'&#13;
NAME='Ubuntu'&#13;
VERSION_ID='22.04'&#13;
VERSION='22.04.4 LTS (Jammy Jellyfish)'&#13;
VERSION_CODENAME=jammy&#13;
ID=ubuntu&#13;
ID_LIKE=debian&#13;
HOME_URL='https://www.ubuntu.com/'&#13;
SUPPORT_URL='https://help.ubuntu.com/'&#13;
BUG_REPORT_URL='https://bugs.launchpad.net/ubuntu/'&#13;
PRIVACY_POLICY_URL='https://www.ubuntu.com/legal/terms-and-policies/privacy-policy'&#13;
UBUNTU_CODENAME=jammy&#13;
wanren@wanren4090:~/tmp_f&#13;
```。</description><guid isPermaLink="true">https://jibinghu.github.io/post/cha-kan-Linux-xi-tong-xiang-xi-ban-ben-xin-xi.html</guid><pubDate>Wed, 13 Nov 2024 04:12:49 +0000</pubDate></item><item><title>查看指定分区硬盘命令</title><link>https://jibinghu.github.io/post/cha-kan-zhi-ding-fen-qu-ying-pan-ming-ling.html</link><description>`df -h /home`&#13;
``` bash&#13;
Filesystem                         Size  Used Avail Use% Mounted on&#13;
/dev/mapper/ubuntu--vg-ubuntu--lv  914G  629G  247G  72% /&#13;
```&#13;
&#13;
---&#13;
&#13;
du 和 df 是两种常用的 Linux 命令，虽然都用于查看存储空间的使用情况，但它们的作用和工作方式有很大的区别：&#13;
&#13;
1. du 命令&#13;
&#13;
	•	全称： Disk Usage（磁盘使用情况）。</description><guid isPermaLink="true">https://jibinghu.github.io/post/cha-kan-zhi-ding-fen-qu-ying-pan-ming-ling.html</guid><pubDate>Wed, 13 Nov 2024 04:09:02 +0000</pubDate></item><item><title>unimrcp 项目架构</title><link>https://jibinghu.github.io/post/unimrcp%20-xiang-mu-jia-gou.html</link><description>UniMRCP 是一个开源项目，旨在跨平台实现媒体资源控制协议（MRCP），符合 IETF 的 RFC6787（MRCPv2）和 RFC4463（MRCPv1）规范。</description><guid isPermaLink="true">https://jibinghu.github.io/post/unimrcp%20-xiang-mu-jia-gou.html</guid><pubDate>Wed, 13 Nov 2024 02:27:02 +0000</pubDate></item><item><title>论文阅读_SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference Acceleration</title><link>https://jibinghu.github.io/post/lun-wen-yue-du-_SageAttention-%20Accurate%208-Bit%20Attention%20for%20Plug-and-play%20Inference%20Acceleration.html</link><description>论文《SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference Acceleration》探讨了在深度学习模型中，尤其是Transformer架构中，注意力机制的计算复杂度问题。</description><guid isPermaLink="true">https://jibinghu.github.io/post/lun-wen-yue-du-_SageAttention-%20Accurate%208-Bit%20Attention%20for%20Plug-and-play%20Inference%20Acceleration.html</guid><pubDate>Tue, 12 Nov 2024 14:25:48 +0000</pubDate></item><item><title>论文阅读_MFFT: A GPU Accelerated Highly Efficient Mixed-Precision Large-Scale FFT Framework</title><link>https://jibinghu.github.io/post/lun-wen-yue-du-_MFFT-%20A%20GPU%20Accelerated%20Highly%20Efficient%20Mixed-Precision%20Large-Scale%20FFT%20Framework.html</link><description>论文地址：https://dl.acm.org/doi/10.1145/3605148&#13;
&#13;
---&#13;
&#13;
GPT-4o 总结：&#13;
&#13;
&gt; https://dl.acm.org/doi/10.1145/3605148&#13;
&#13;
&gt; 分点详细总结这篇问题的场景、作用和创新点&#13;
&#13;
该论文针对在GPU集群上执行大规模快速傅里叶变换（FFT）时的性能瓶颈，提出了一种名为MFFT的高效混合精度FFT框架。</description><guid isPermaLink="true">https://jibinghu.github.io/post/lun-wen-yue-du-_MFFT-%20A%20GPU%20Accelerated%20Highly%20Efficient%20Mixed-Precision%20Large-Scale%20FFT%20Framework.html</guid><pubDate>Tue, 12 Nov 2024 14:10:47 +0000</pubDate></item><item><title>论文阅读_A novel HPL-AI approach for FP16-only accelerator and its instantiation on Kunpeng+Ascend AI-specific platform</title><link>https://jibinghu.github.io/post/lun-wen-yue-du-_A%20novel%20HPL-AI%20approach%20for%20FP16-only%20accelerator%20and%20its%20instantiation%20on%20Kunpeng%2BAscend%20AI-specific%20platform.html</link><description>论文地址：https://dl.acm.org/doi/10.1016/j.jpdc.2024.104884&#13;
&#13;
---&#13;
&#13;
GPT-4o总结：&#13;
&#13;
&gt; https://dl.acm.org/doi/10.1016/j.jpdc.2024.104884&#13;
&gt; &#13;
&gt; 总结这篇问题的场景、作用和创新点&#13;
&#13;
根据您提供的DOI信息，论文标题为“针对仅支持FP16加速器的新型HPL-AI方法及其在Kunpeng+Ascend AI专用平台上的实现”。</description><guid isPermaLink="true">https://jibinghu.github.io/post/lun-wen-yue-du-_A%20novel%20HPL-AI%20approach%20for%20FP16-only%20accelerator%20and%20its%20instantiation%20on%20Kunpeng%2BAscend%20AI-specific%20platform.html</guid><pubDate>Tue, 12 Nov 2024 14:02:46 +0000</pubDate></item><item><title>MRCP/SIP/RTP协议</title><link>https://jibinghu.github.io/post/MRCP-SIP-RTP-xie-yi.html</link><description>### MRCP、SIP 和 RTP 是在现代通信系统中经常组合使用的三个协议，尤其在语音识别（ASR）、文本转语音（TTS）和呼叫中心等系统中。</description><guid isPermaLink="true">https://jibinghu.github.io/post/MRCP-SIP-RTP-xie-yi.html</guid><pubDate>Tue, 12 Nov 2024 10:36:03 +0000</pubDate></item><item><title>Linux 使用日常：find 重点标注</title><link>https://jibinghu.github.io/post/Linux%20-shi-yong-ri-chang-%EF%BC%9Afind%20-zhong-dian-biao-zhu.html</link><description>查找特定文件/文件夹，筛选所选信息并将重点信息标红：&#13;
&#13;
`find / -name '* search_content*' 2&gt;/dev/null | grep --color=always 'search_content'`&#13;
&#13;
&#13;
`find / -name '*search_content*' -printf '\033[1;31m%p\033[0m\n' 2&gt;/dev/null`&#13;
&#13;
这里将 find 的输出高亮设置为红色 (\033[1;31m)，可以根据需要修改颜色。</description><guid isPermaLink="true">https://jibinghu.github.io/post/Linux%20-shi-yong-ri-chang-%EF%BC%9Afind%20-zhong-dian-biao-zhu.html</guid><pubDate>Tue, 12 Nov 2024 08:59:26 +0000</pubDate></item><item><title>面试回顾 -&gt; RAG中搜索效果不好如何解决</title><link>https://jibinghu.github.io/post/mian-shi-hui-gu-%20--%20RAG-zhong-sou-suo-xiao-guo-bu-hao-ru-he-jie-jue.html</link><description>如果通过 RAG（Retrieval-Augmented Generation）检索出来的内容效果不理想，可以尝试以下改进措施：&#13;
&#13;
1. 改进检索库质量&#13;
&#13;
- 提升文档质量：确保用于检索的文档准确、相关、清晰，剔除低质量、不相关的文档。</description><guid isPermaLink="true">https://jibinghu.github.io/post/mian-shi-hui-gu-%20--%20RAG-zhong-sou-suo-xiao-guo-bu-hao-ru-he-jie-jue.html</guid><pubDate>Fri, 08 Nov 2024 07:25:54 +0000</pubDate></item><item><title>面试回顾 -&gt; C++中怎样判断两个浮点数相等</title><link>https://jibinghu.github.io/post/mian-shi-hui-gu-%20--%20C%2B%2B-zhong-zen-yang-pan-duan-liang-ge-fu-dian-shu-xiang-deng.html</link><description>### C++中怎样判断两个浮点数相等&#13;
&#13;
在 C++ 中，判断两个浮点数是否相等时，由于浮点数在存储中的精度问题，直接比较可能会导致不准确的结果。</description><guid isPermaLink="true">https://jibinghu.github.io/post/mian-shi-hui-gu-%20--%20C%2B%2B-zhong-zen-yang-pan-duan-liang-ge-fu-dian-shu-xiang-deng.html</guid><pubDate>Fri, 08 Nov 2024 07:24:12 +0000</pubDate></item><item><title>C++ 中的实例化回顾</title><link>https://jibinghu.github.io/post/C%2B%2B%20-zhong-de-shi-li-hua-hui-gu.html</link><description>### 普通实例化&#13;
&#13;
在 C++ 中，struct 和 class 在实例化时的语法是相同的。</description><guid isPermaLink="true">https://jibinghu.github.io/post/C%2B%2B%20-zhong-de-shi-li-hua-hui-gu.html</guid><pubDate>Fri, 08 Nov 2024 06:47:08 +0000</pubDate></item><item><title>Github 推送错误解决</title><link>https://jibinghu.github.io/post/Github%20-tui-song-cuo-wu-jie-jue.html</link><description>在正常使用 `git push origin` 向 repo 推送时发现报错如下：&#13;
&#13;
``` bash&#13;
[main da5bafe] 11/8/01&#13;
 3 files changed, 55 insertions(+)&#13;
 create mode 100644 cpp_prac/Cpython_bind/Cpython.cpp&#13;
 create mode 100644 cpp_prac/Cpython_bind/Cpython.py&#13;
 create mode 100755 cpp_prac/Cpython_bind/demo_module.so&#13;
(py310) binghu@iscashpc:~/leetcode$ git push origin&#13;
Missing or invalid credentials.&#13;
Error: connect ECONNREFUSED /run/user/1006/vscode-git-8f5a0a4c40.sock&#13;
    at PipeConnectWrap.afterConnect [as oncomplete] (node:net:1607:16) {&#13;
  errno: -111,&#13;
  code: 'ECONNREFUSED',&#13;
  syscall: 'connect',&#13;
  address: '/run/user/1006/vscode-git-8f5a0a4c40.sock'&#13;
}&#13;
Missing or invalid credentials.&#13;
Error: connect ECONNREFUSED /run/user/1006/vscode-git-8f5a0a4c40.sock&#13;
    at PipeConnectWrap.afterConnect [as oncomplete] (node:net:1607:16) {&#13;
  errno: -111,&#13;
  code: 'ECONNREFUSED',&#13;
  syscall: 'connect',&#13;
  address: '/run/user/1006/vscode-git-8f5a0a4c40.sock'&#13;
}&#13;
remote: No anonymous write access.&#13;
fatal: Authentication failed for 'https://github.com/jibinghu/leetcode/'&#13;
```&#13;
&#13;
显然是身份验证不通过，但使用 `ssh -T git@github.com` remote github时返回：&#13;
&#13;
`Hi jibinghu! You've successfully authenticated, but GitHub does not provide shell access.`&#13;
&#13;
说明密钥是正确的，`git remote -v` 检查：&#13;
&#13;
``` bash&#13;
origin  https://github.com/jibinghu/leetcode (fetch)&#13;
origin  https://github.com/jibinghu/leetcode (push)&#13;
```&#13;
&#13;
&gt; 身份验证已经通过。</description><guid isPermaLink="true">https://jibinghu.github.io/post/Github%20-tui-song-cuo-wu-jie-jue.html</guid><pubDate>Fri, 08 Nov 2024 04:27:54 +0000</pubDate></item><item><title>C程序通过 CPython 绑定</title><link>https://jibinghu.github.io/post/C-cheng-xu-tong-guo-%20CPython%20-bang-ding.html</link><description>在 Python 中使用 C++ 实现代码并将其注册为 Python 可调用的扩展模块，可以通过 CPython（Python 的 C API 实现）来实现。</description><guid isPermaLink="true">https://jibinghu.github.io/post/C-cheng-xu-tong-guo-%20CPython%20-bang-ding.html</guid><pubDate>Thu, 07 Nov 2024 14:35:58 +0000</pubDate></item><item><title>搜广推算法总结</title><link>https://jibinghu.github.io/post/sou-guang-tui-suan-fa-zong-jie.html</link><description>搜广推（搜索、广告、推荐）领域是互联网和计算领域的重要组成部分，涉及多种算法来提高用户体验和商业效益。</description><guid isPermaLink="true">https://jibinghu.github.io/post/sou-guang-tui-suan-fa-zong-jie.html</guid><pubDate>Thu, 07 Nov 2024 07:57:14 +0000</pubDate></item><item><title>3A-NPC行为逻辑</title><link>https://jibinghu.github.io/post/3A-NPC-xing-wei-luo-ji.html</link><description>在类似《只狼》这样的3A游戏中，NPC（非玩家角色）的行为逻辑是由多层次的人工智能（AI）系统设计和实现的，旨在创造出令人信服且具有挑战性的游戏体验。</description><guid isPermaLink="true">https://jibinghu.github.io/post/3A-NPC-xing-wei-luo-ji.html</guid><pubDate>Thu, 07 Nov 2024 07:54:42 +0000</pubDate></item><item><title>FAQ in Transformer</title><link>https://jibinghu.github.io/post/FAQ%20in%20Transformer.html</link><description>### 如何理解 Transformers 中 FFNs 的作用？&#13;
&#13;
- attention会混合多个token的信息来提取特征，但每个channel（feature dimension）保持独立。</description><guid isPermaLink="true">https://jibinghu.github.io/post/FAQ%20in%20Transformer.html</guid><pubDate>Thu, 07 Nov 2024 07:31:02 +0000</pubDate></item><item><title>推荐算法简介</title><link>https://jibinghu.github.io/post/tui-jian-suan-fa-jian-jie.html</link><description>推荐算法领域的研究内容广泛，涉及机器学习、深度学习、信息检索、数据挖掘等多个方向。</description><guid isPermaLink="true">https://jibinghu.github.io/post/tui-jian-suan-fa-jian-jie.html</guid><pubDate>Wed, 06 Nov 2024 09:31:15 +0000</pubDate></item><item><title>计算机体系结构、并行与分布计算、存储系统领域的国际学术期刊和会议列表</title><link>https://jibinghu.github.io/post/ji-suan-ji-ti-xi-jie-gou-%E3%80%81-bing-xing-yu-fen-bu-ji-suan-%E3%80%81-cun-chu-xi-tong-ling-yu-de-guo-ji-xue-shu-qi-kan-he-hui-yi-lie-biao.html</link><description>### 中国计算机学会（CCF）推荐的计算机体系结构、并行与分布计算、存储系统领域的国际学术期刊和会议列表&#13;
&#13;
---&#13;
&#13;
#### A类期刊：&#13;
&#13;
- **ACM Transactions on Computer Systems (TOCS)**  &#13;
  出版社：ACM  &#13;
  简介：研究计算机系统的设计、实现和分析，重点关注系统的结构、性能和可靠性。</description><guid isPermaLink="true">https://jibinghu.github.io/post/ji-suan-ji-ti-xi-jie-gou-%E3%80%81-bing-xing-yu-fen-bu-ji-suan-%E3%80%81-cun-chu-xi-tong-ling-yu-de-guo-ji-xue-shu-qi-kan-he-hui-yi-lie-biao.html</guid><pubDate>Tue, 05 Nov 2024 12:41:32 +0000</pubDate></item><item><title>CUDA Graph</title><link>https://jibinghu.github.io/post/CUDA%20Graph.html</link><description>使用 CUDA 图（CUDA Graph）来加速向量加法操作的示例。</description><guid isPermaLink="true">https://jibinghu.github.io/post/CUDA%20Graph.html</guid><pubDate>Mon, 04 Nov 2024 14:25:09 +0000</pubDate></item><item><title>卷积核的通道数和个数与输入、输出的关系</title><link>https://jibinghu.github.io/post/juan-ji-he-de-tong-dao-shu-he-ge-shu-yu-shu-ru-%E3%80%81-shu-chu-de-guan-xi.html</link><description>在卷积操作中，卷积核的通道数和个数与输入、输出的关系如下：&#13;
&#13;
	1.	卷积核的通道数：&#13;
	•	卷积核的通道数必须与输入特征图的通道数相同。</description><guid isPermaLink="true">https://jibinghu.github.io/post/juan-ji-he-de-tong-dao-shu-he-ge-shu-yu-shu-ru-%E3%80%81-shu-chu-de-guan-xi.html</guid><pubDate>Mon, 04 Nov 2024 06:41:07 +0000</pubDate></item><item><title>ollama 源码编译相关</title><link>https://jibinghu.github.io/post/ollama%20-yuan-ma-bian-yi-xiang-guan.html</link><description>编译指南：https://blog.csdn.net/skywalk8163/article/details/140390925。</description><guid isPermaLink="true">https://jibinghu.github.io/post/ollama%20-yuan-ma-bian-yi-xiang-guan.html</guid><pubDate>Mon, 04 Nov 2024 05:18:25 +0000</pubDate></item><item><title>终端可以连接 SSH Remote ，但 VSCode 一直卡在初始化下载</title><link>https://jibinghu.github.io/post/zhong-duan-ke-yi-lian-jie-%20SSH%20Remote%20%EF%BC%8C-dan-%20VSCode%20-yi-zhi-qia-zai-chu-shi-hua-xia-zai.html</link><description>其实观察log也可以看出来，如果不是 .vscode-serve 的问题的话，就是服务器空间不够了。</description><guid isPermaLink="true">https://jibinghu.github.io/post/zhong-duan-ke-yi-lian-jie-%20SSH%20Remote%20%EF%BC%8C-dan-%20VSCode%20-yi-zhi-qia-zai-chu-shi-hua-xia-zai.html</guid><pubDate>Mon, 04 Nov 2024 04:44:02 +0000</pubDate></item><item><title>Python 双端队列</title><link>https://jibinghu.github.io/post/Python%20-shuang-duan-dui-lie.html</link><description>from collections import deque 是用于导入 Python 标准库 collections 中的 deque（双端队列）的语句。</description><guid isPermaLink="true">https://jibinghu.github.io/post/Python%20-shuang-duan-dui-lie.html</guid><pubDate>Sun, 03 Nov 2024 14:39:21 +0000</pubDate></item><item><title>STL -&gt; vector 方法记录</title><link>https://jibinghu.github.io/post/STL%20--%20vector%20-fang-fa-ji-lu.html</link><description>std::vector 提供了许多有用的成员函数，可以方便地操作和访问元素。</description><guid isPermaLink="true">https://jibinghu.github.io/post/STL%20--%20vector%20-fang-fa-ji-lu.html</guid><pubDate>Sun, 03 Nov 2024 09:01:19 +0000</pubDate></item><item><title>拓扑排序</title><link>https://jibinghu.github.io/post/tuo-pu-pai-xu.html</link><description>以下是一个简单的 C++ 程序，用于构建一个有向无环图（DAG）的拓扑结构，并验证是否可以正确进行拓扑排序。</description><guid isPermaLink="true">https://jibinghu.github.io/post/tuo-pu-pai-xu.html</guid><pubDate>Sun, 03 Nov 2024 07:02:34 +0000</pubDate></item><item><title>关于前/中/后缀表示式的概念/算法实现</title><link>https://jibinghu.github.io/post/guan-yu-qian---zhong---hou-zhui-biao-shi-shi-de-gai-nian---suan-fa-shi-xian.html</link><description>前缀表达式、中缀表达式和后缀表达式是三种不同的算术表达式表示方式，它们主要区别在于运算符相对于操作数的位置。</description><guid isPermaLink="true">https://jibinghu.github.io/post/guan-yu-qian---zhong---hou-zhui-biao-shi-shi-de-gai-nian---suan-fa-shi-xian.html</guid><pubDate>Fri, 01 Nov 2024 07:08:08 +0000</pubDate></item><item><title>重新激活ollama配置</title><link>https://jibinghu.github.io/post/zhong-xin-ji-huo-ollama-pei-zhi.html</link><description>在配置完 /etc/systemd/system/ollama.service 文件后，可以通过以下步骤激活并启动该服务：&#13;
&#13;
1. 重新加载 systemd 配置&#13;
&#13;
首先，需要重新加载 systemd 的配置，以便 systemd 识别新的服务文件：&#13;
&#13;
sudo systemctl daemon-reload&#13;
&#13;
2. 启动服务&#13;
&#13;
重新加载配置后，可以使用以下命令启动 ollama 服务：&#13;
&#13;
sudo systemctl start ollama.service&#13;
&#13;
3. 设置开机自启动（可选）&#13;
&#13;
如果希望在系统启动时自动启动 ollama 服务，可以启用自启动：&#13;
&#13;
sudo systemctl enable ollama.service&#13;
&#13;
4. 检查服务状态&#13;
&#13;
可以使用以下命令检查服务是否启动成功：&#13;
&#13;
sudo systemctl status ollama.service&#13;
&#13;
这将显示 ollama 服务的当前状态和日志。</description><guid isPermaLink="true">https://jibinghu.github.io/post/zhong-xin-ji-huo-ollama-pei-zhi.html</guid><pubDate>Fri, 01 Nov 2024 06:09:19 +0000</pubDate></item><item><title>检查程序运行时环境变量(以Ollama为例)</title><link>https://jibinghu.github.io/post/jian-cha-cheng-xu-yun-xing-shi-huan-jing-bian-liang-%28-yi-Ollama-wei-li-%29.html</link><description>这个命令用于查看进程ID为 4368 的进程中，所有与 OLLAMA_ 相关的环境变量及其值。</description><guid isPermaLink="true">https://jibinghu.github.io/post/jian-cha-cheng-xu-yun-xing-shi-huan-jing-bian-liang-%28-yi-Ollama-wei-li-%29.html</guid><pubDate>Fri, 01 Nov 2024 06:01:46 +0000</pubDate></item><item><title>scaled_dot_product_attention</title><link>https://jibinghu.github.io/post/scaled_dot_product_attention.html</link><description># scaled_dot_product_attention&#13;
torch 中的 scaled_dot_product_attention 是 PyTorch 2.0 中引入的最优 Attention 接口之一，旨在通过硬件加速和优化的计算图，加速模型训练与推理。</description><guid isPermaLink="true">https://jibinghu.github.io/post/scaled_dot_product_attention.html</guid><pubDate>Thu, 31 Oct 2024 13:15:14 +0000</pubDate></item><item><title>Lambda函数</title><link>https://jibinghu.github.io/post/Lambda-han-shu.html</link><description>Lambda函数是C++11引入的一种简洁的匿名函数，用于临时定义一次性的小函数。</description><guid isPermaLink="true">https://jibinghu.github.io/post/Lambda-han-shu.html</guid><pubDate>Thu, 31 Oct 2024 06:44:31 +0000</pubDate></item><item><title>ConvStencil: Transform Stencil Computation to Matrix Multiplication on Tensor Cores</title><link>https://jibinghu.github.io/post/ConvStencil-%20Transform%20Stencil%20Computation%20to%20Matrix%20Multiplication%20on%20Tensor%20Cores.html</link><description>ConvStencil: Transform Stencil Computation to Matrix Multiplication on Tensor Cores&#13;
&#13;
链接：https://dl.acm.org/doi/pdf/10.1145/3627535.3638476&#13;
引用：Yuetao Chen, Kun Li, Yuhao Wang, Donglin Bai, Lei Wang, Lingxiao Ma, Liang Yuan, Yunquan Zhang, Ting Cao, and Mao Yang. 2024. ConvStencil: Transform Stencil Computation to Matrix Multiplication on Tensor Cores. In Proceedings of the 29th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming (PPoPP '24). Association for Computing Machinery, New York, NY, USA, 333–347. https://doi.org/10.1145/3627535.3638476&#13;
&#13;
---&#13;
&#13;
不要钻牛角尖，细节的东西暂时不需要花大把时间去考虑。</description><guid isPermaLink="true">https://jibinghu.github.io/post/ConvStencil-%20Transform%20Stencil%20Computation%20to%20Matrix%20Multiplication%20on%20Tensor%20Cores.html</guid><pubDate>Mon, 21 Oct 2024 14:50:32 +0000</pubDate></item><item><title>分组卷积</title><link>https://jibinghu.github.io/post/fen-zu-juan-ji.html</link><description>&lt;a href='https://paddlepedia.readthedocs.io/en/latest/tutorials/CNN/convolution_operator/Group_Convolution.html'&gt;PaddlePaddle深度学习知识&lt;/a&gt;&#13;
---&#13;
### 分组卷积&#13;
&#13;
对于尺寸为 𝐻1×𝑊1×𝐶1&#13;
 的输入矩阵，当标准卷积核的尺寸为 ℎ1×𝑤1×𝐶1&#13;
 ，共有 𝐶2&#13;
 个标准卷积核时，标准卷积会对完整的输入数据进行运算，最终得到的输出矩阵尺寸为 𝐻2×𝑊2×𝐶2&#13;
 。</description><guid isPermaLink="true">https://jibinghu.github.io/post/fen-zu-juan-ji.html</guid><pubDate>Mon, 21 Oct 2024 04:09:57 +0000</pubDate></item><item><title>C++智能指针</title><link>https://jibinghu.github.io/post/C%2B%2B-zhi-neng-zhi-zhen.html</link><description>智能指针是C++中的一种用于自动管理动态内存的指针，它们能够自动释放不再使用的对象，避免内存泄漏。</description><guid isPermaLink="true">https://jibinghu.github.io/post/C%2B%2B-zhi-neng-zhi-zhen.html</guid><pubDate>Thu, 17 Oct 2024 06:05:51 +0000</pubDate></item><item><title>每日翻译！</title><link>https://jibinghu.github.io/post/mei-ri-fan-yi-%EF%BC%81.html</link><description>文言文：&#13;
- 行当务之事，亦宜分神以探未来之道，扩展格局。</description><guid isPermaLink="true">https://jibinghu.github.io/post/mei-ri-fan-yi-%EF%BC%81.html</guid><pubDate>Tue, 15 Oct 2024 13:54:21 +0000</pubDate></item><item><title>Pooling 层 -&gt; TEST</title><link>https://jibinghu.github.io/post/Pooling%20-ceng-%20--%20TEST.html</link><description>基于 Torch 的脚本：&#13;
``` python&#13;
import torch&#13;
import torch.nn as nn&#13;
&#13;
# Create a sample tensor (2D)&#13;
input_tensor = torch.tensor([[1., 2., 3., 4.],&#13;
                             [5., 6., 7., 8.],&#13;
                             [9., 10., 11., 12.],&#13;
                             [13., 14., 15., 16.]])&#13;
&#13;
# Reshape the tensor to 1x1x4x4 (as expected by pooling layers for 2D input)&#13;
input_tensor = input_tensor.unsqueeze(0).unsqueeze(0)&#13;
&#13;
# Max Pooling with padding&#13;
max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)&#13;
max_pooled_output = max_pool(input_tensor)&#13;
&#13;
# Average Pooling with padding&#13;
# avg_pool = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)&#13;
# avg_pooled_output = avg_pool(input_tensor)&#13;
&#13;
print('Input Tensor:\n', input_tensor)&#13;
print('\nMax Pooled Output with Padding:\n', max_pooled_output)&#13;
print('\nAverage Pooled Output with Padding:\n', avg_pooled_output)&#13;
```&#13;
&#13;
---&#13;
&#13;
### 4 * 4 的 Pooling 层是比较典型的，所以进行多方面测试：&#13;
&#13;
- **kernel_size=2, stride=2, padding=0：**&#13;
``` bash&#13;
Max Pooled Output with Padding:&#13;
 tensor([[[[ 6.,  7.,  8.],&#13;
          [10., 11., 12.],&#13;
          [14., 15., 16.]]]])&#13;
```&#13;
这部分还是没有异议的，当Stride=1时从开头进行Pooling；&#13;
- **kernel_size=2, stride=2, padding=0：**&#13;
``` bash&#13;
 tensor([[[[ 6.,  8.],&#13;
          [14., 16.]]]])&#13;
```&#13;
当Stride足够覆盖一次时，也是没有异议的。</description><guid isPermaLink="true">https://jibinghu.github.io/post/Pooling%20-ceng-%20--%20TEST.html</guid><pubDate>Tue, 15 Oct 2024 13:42:40 +0000</pubDate></item><item><title>每日翻译！</title><link>https://jibinghu.github.io/post/mei-ri-fan-yi-%EF%BC%81.html</link><description>文言文：&#13;
&#13;
持志如焚，持行如矢，志不改，行不止。</description><guid isPermaLink="true">https://jibinghu.github.io/post/mei-ri-fan-yi-%EF%BC%81.html</guid><pubDate>Mon, 14 Oct 2024 14:56:47 +0000</pubDate></item><item><title>C++设计模式之单例模式与工厂模式</title><link>https://jibinghu.github.io/post/C%2B%2B-she-ji-mo-shi-zhi-dan-li-mo-shi-yu-gong-chang-mo-shi.html</link><description>1. 单例模式（Singleton Pattern）&#13;
&#13;
单例模式是一种设计模式，保证在应用程序的生命周期内，一个类只有一个实例，并且提供一个全局访问点来获取这个实例。</description><guid isPermaLink="true">https://jibinghu.github.io/post/C%2B%2B-she-ji-mo-shi-zhi-dan-li-mo-shi-yu-gong-chang-mo-shi.html</guid><pubDate>Mon, 14 Oct 2024 07:42:14 +0000</pubDate></item><item><title>C++结构化绑定</title><link>https://jibinghu.github.io/post/C%2B%2B-jie-gou-hua-bang-ding.html</link><description>## C++ 17 结构化绑定&#13;
&#13;
stl 的 map 容器很多读者应该都很熟悉，map 容器提供了一个 **insert** 方法，我们用该方法向 map 中插入元素，但是应该很少有人记得 **insert** 方法的返回值是什么类型，让我们来看一下 C++98/03 提供的 **insert** 方法的签名：&#13;
&#13;
```&#13;
std::pair&lt;iterator,bool&gt; insert( const value_type&amp; value );&#13;
```&#13;
&#13;
这里我们仅关心其返回值，这个返回值是一个 **std::pair** 类型，由于 map 中的元素的 key 不允许重复，所以如果 insert 方法调用成功，T1 是被成功插入到 map 中的元素的迭代器，T2 的类型为 bool，此时其值为 true（表示插入成功）；如果 insert 由于 key 重复，T1 是造成 insert 插入失败、已经存在于 map 中的元素的迭代器，此时 T2 的值为 false（表示插入失败）。</description><guid isPermaLink="true">https://jibinghu.github.io/post/C%2B%2B-jie-gou-hua-bang-ding.html</guid><pubDate>Fri, 11 Oct 2024 05:24:46 +0000</pubDate></item><item><title>`GLIBCXX_3.4.32' not found" error at runtime. GCC 13.2.0 问题的解决方式：StackOverflow</title><link>https://jibinghu.github.io/post/%60GLIBCXX_3.4.32%27%20not%20found-%20error%20at%20runtime.%20GCC%2013.2.0%20-wen-ti-de-jie-jue-fang-shi-%EF%BC%9AStackOverflow.html</link><description>&gt; the /lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.32' is for gcc13, so we need to update this file.`&#13;
&#13;
0. 查看当前 GLIBCXX 版本&#13;
首先通过命令`strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBCXX`&#13;
- strings：这是一个 Linux 命令，用于提取二进制文件或库文件中可打印的字符串。</description><guid isPermaLink="true">https://jibinghu.github.io/post/%60GLIBCXX_3.4.32%27%20not%20found-%20error%20at%20runtime.%20GCC%2013.2.0%20-wen-ti-de-jie-jue-fang-shi-%EF%BC%9AStackOverflow.html</guid><pubDate>Thu, 10 Oct 2024 13:27:18 +0000</pubDate></item><item><title>C++ 中常用的检查宏：CHECK系列 -&gt; 标准库/glog库 &lt;&lt; 单元测试；std::function </title><link>https://jibinghu.github.io/post/C%2B%2B%20-zhong-chang-yong-de-jian-cha-hong-%EF%BC%9ACHECK-xi-lie-%20--%20-biao-zhun-ku--glog-ku-%20--%20-dan-yuan-ce-shi-%EF%BC%9Bstd--function%20.html</link><description>在C++中，类似于`CHECK_LT`的断言方法通常用于验证条件，并在条件不满足时触发错误或异常。</description><guid isPermaLink="true">https://jibinghu.github.io/post/C%2B%2B%20-zhong-chang-yong-de-jian-cha-hong-%EF%BC%9ACHECK-xi-lie-%20--%20-biao-zhun-ku--glog-ku-%20--%20-dan-yuan-ce-shi-%EF%BC%9Bstd--function%20.html</guid><pubDate>Wed, 09 Oct 2024 08:06:20 +0000</pubDate></item><item><title>类模板的特化 #举例</title><link>https://jibinghu.github.io/post/lei-mo-ban-de-te-hua-%20%23-ju-li.html</link><description>### 例子：通用 `Array` 类和 `bool` 类型的特化&#13;
&#13;
创建一个通用的 `Array` 类模板，它可以存储任意类型的数据。</description><guid isPermaLink="true">https://jibinghu.github.io/post/lei-mo-ban-de-te-hua-%20%23-ju-li.html</guid><pubDate>Wed, 09 Oct 2024 03:38:54 +0000</pubDate></item><item><title>单目深度估计</title><link>https://jibinghu.github.io/post/dan-mu-shen-du-gu-ji.html</link><description>**单目深度估计**（Monocular Depth Estimation）是计算机视觉中的一个经典任务，目标是通过一张单目摄像头（即仅包含一个视角的二维图像）来估计场景中每个像素的深度信息。</description><guid isPermaLink="true">https://jibinghu.github.io/post/dan-mu-shen-du-gu-ji.html</guid><pubDate>Mon, 09 Sep 2024 07:37:00 +0000</pubDate></item><item><title>ONNX配置参数说明（v1）</title><link>https://jibinghu.github.io/post/ONNX-pei-zhi-can-shu-shuo-ming-%EF%BC%88v1%EF%BC%89.html</link><description>ONNX配置参数说明（v1）&#13;
&#13;
torch Version 2.1.0 的 export参数：&#13;
``` python&#13;
def export(&#13;
    model: Union[torch.nn.Module, torch.jit.ScriptModule, torch.jit.ScriptFunction],&#13;
    args: Union[Tuple[Any, ...], torch.Tensor],&#13;
    f: Union[str, io.BytesIO],&#13;
    export_params: bool = True,&#13;
    verbose: bool = False,&#13;
    training: _C_onnx.TrainingMode = _C_onnx.TrainingMode.EVAL,&#13;
    input_names: Optional[Sequence[str]] = None,&#13;
    output_names: Optional[Sequence[str]] = None,&#13;
    operator_export_type: _C_onnx.OperatorExportTypes = _C_onnx.OperatorExportTypes.ONNX,&#13;
    opset_version: Optional[int] = None,&#13;
    do_constant_folding: bool = True,&#13;
    dynamic_axes: Optional[&#13;
        Union[Mapping[str, Mapping[int, str]], Mapping[str, Sequence[int]]]&#13;
    ] = None,&#13;
    keep_initializers_as_inputs: Optional[bool] = None,&#13;
    custom_opsets: Optional[Mapping[str, int]] = None,&#13;
    export_modules_as_functions: Union[bool, Collection[Type[torch.nn.Module]]] = False,&#13;
    autograd_inlining: Optional[bool] = True,&#13;
)&#13;
```&#13;
&#13;
model: pytorch模型&#13;
args: 第一个参数model的输入数据，因为模型的输入可能不止一个，因此采用元组作为参数&#13;
export_params: 导出的onnx模型文件可以包含网络结构与权重参数，如果设置该参数为False，则导出的onnx模型文件只包含网络结构，因此，一般保持默认为True即可&#13;
verbose: 该参数如果指定为True，则在导出onnx的过程中会打印详细的导出过程信息&#13;
&#13;
opset_version: ONNX的算子集版本，默认为11。</description><guid isPermaLink="true">https://jibinghu.github.io/post/ONNX-pei-zhi-can-shu-shuo-ming-%EF%BC%88v1%EF%BC%89.html</guid><pubDate>Tue, 03 Sep 2024 13:54:39 +0000</pubDate></item><item><title>CUDA 编程模型中的 Block 的共享内存与 SM 的L1 Cache和Shared Memory</title><link>https://jibinghu.github.io/post/CUDA%20-bian-cheng-mo-xing-zhong-de-%20Block%20-de-gong-xiang-nei-cun-yu-%20SM%20-de-L1%20Cache-he-Shared%20Memory.html</link><description>### CUDA 编程模型中的 Block 的共享内存与 SM 的L1 Cache和Shared Memory有什么区别和联系？&#13;
&#13;
在 CUDA 编程模型中，Block 的共享内存（Shared Memory）与 SM（Streaming Multiprocessor）的 L1 Cache 和 Shared Memory 是两个重要的内存层级，它们在用途、性能和实现上都有所不同。</description><guid isPermaLink="true">https://jibinghu.github.io/post/CUDA%20-bian-cheng-mo-xing-zhong-de-%20Block%20-de-gong-xiang-nei-cun-yu-%20SM%20-de-L1%20Cache-he-Shared%20Memory.html</guid><pubDate>Mon, 02 Sep 2024 06:06:48 +0000</pubDate></item><item><title>NV知识库(SASS和PTX中间代码)</title><link>https://jibinghu.github.io/post/NV-zhi-shi-ku-%28SASS-he-PTX-zhong-jian-dai-ma-%29.html</link><description>### SASS 和 PTX&#13;
&#13;
SASS(Streaming Assembler) 和 PTX(Parallel Thread Execution)都是 NVIDIA CUDA 编程模型中的组件，处于不同的抽象层次。</description><guid isPermaLink="true">https://jibinghu.github.io/post/NV-zhi-shi-ku-%28SASS-he-PTX-zhong-jian-dai-ma-%29.html</guid><pubDate>Wed, 28 Aug 2024 10:11:47 +0000</pubDate></item><item><title> How_to_optimize_in_GPU_GEMM_(二)</title><link>https://jibinghu.github.io/post/%20How_to_optimize_in_GPU_GEMM_%28-er-%29.html</link><description>&lt;a href='https://github.com/Liu-xiandong/How_to_optimize_in_GPU'&gt; How_to_optimize_in_GPU_GEMM_(二)_评论分析&lt;/a&gt;&#13;
---&#13;
你好想问一下看起来并没有用异步的指令为什么可以实现数据预取呢&#13;
&gt; pipeline 双缓冲 pingpong操作，一个事情，都是为了实现计算和访存错开。</description><guid isPermaLink="true">https://jibinghu.github.io/post/%20How_to_optimize_in_GPU_GEMM_%28-er-%29.html</guid><pubDate>Sun, 25 Aug 2024 14:50:34 +0000</pubDate></item><item><title>海光 DCU 相关知识</title><link>https://jibinghu.github.io/post/hai-guang-%20DCU%20-xiang-guan-zhi-shi.html</link><description>&gt; 目前还是在学习阶段，把之后可能时常需要用到的技术备忘在这里。</description><guid isPermaLink="true">https://jibinghu.github.io/post/hai-guang-%20DCU%20-xiang-guan-zhi-shi.html</guid><pubDate>Fri, 23 Aug 2024 14:51:13 +0000</pubDate></item><item><title>C++模板的使用</title><link>https://jibinghu.github.io/post/C%2B%2B-mo-ban-de-shi-yong.html</link><description>模板是C++支持[参数化](https://so.csdn.net/so/search?q=%E5%8F%82%E6%95%B0%E5%8C%96&amp;spm=1001.2101.3001.7020)多态的工具，模板的参数有三种类型：类型参数、非类型参数和模板类型参数。</description><guid isPermaLink="true">https://jibinghu.github.io/post/C%2B%2B-mo-ban-de-shi-yong.html</guid><pubDate>Fri, 23 Aug 2024 07:46:25 +0000</pubDate></item><item><title>AWQ量化</title><link>https://jibinghu.github.io/post/AWQ-liang-hua.html</link><description>挑选显著权重：权重矩阵的一行作为一个单位。</description><guid isPermaLink="true">https://jibinghu.github.io/post/AWQ-liang-hua.html</guid><pubDate>Wed, 21 Aug 2024 09:51:57 +0000</pubDate></item><item><title>基座模型私有数据训练</title><link>https://jibinghu.github.io/post/ji-zuo-mo-xing-si-you-shu-ju-xun-lian.html</link><description>针对基座模型（例如大型语言模型）进行私有数据训练，以下是几种代价较小的方式：&#13;
&#13;
1. QLoRA 微调&#13;
- 概念：QLoRA（Quantized Low Rank Adaptation）是一种利用低秩矩阵分解和量化技术的微调方法，能够在模型参数显著减少的情况下，实现类似全量模型微调的效果。</description><guid isPermaLink="true">https://jibinghu.github.io/post/ji-zuo-mo-xing-si-you-shu-ju-xun-lian.html</guid><pubDate>Wed, 21 Aug 2024 09:50:57 +0000</pubDate></item><item><title>Pre-Norm&amp;Post-Norm</title><link>https://jibinghu.github.io/post/Pre-Norm%26Post-Norm.html</link><description>![](https://img2024.cnblogs.com/blog/3358182/202407/3358182-20240717110533959-1175740727.png)&#13;
&#13;
&#13;
从图中可以看出，两种不同的Transformer结构：Post-Norm Residual Unit 和 Pre-Norm Residual Unit。</description><guid isPermaLink="true">https://jibinghu.github.io/post/Pre-Norm%26Post-Norm.html</guid><pubDate>Wed, 17 Jul 2024 03:07:42 +0000</pubDate></item><item><title>CUDA binary analysis utils</title><link>https://jibinghu.github.io/post/CUDA%20binary%20analysis%20utils.html</link><description>cuobjdump ：&#13;
cuobjdump 是 NVIDIA 提供的一个工具，用于提取和显示 CUDA 二进制文件（即 CUDA 应用程序的可执行文件）中的信，可以用来分析cubin文件和host文件。</description><guid isPermaLink="true">https://jibinghu.github.io/post/CUDA%20binary%20analysis%20utils.html</guid><pubDate>Tue, 16 Jul 2024 08:21:47 +0000</pubDate></item><item><title>C++中间件介绍</title><link>https://jibinghu.github.io/post/C%2B%2B-zhong-jian-jian-jie-shao.html</link><description>以下是对RPC、Nginx、MongoDB、MQ和HAProxy的解释：&#13;
&#13;
### 1. RPC（Remote Procedure Call）&#13;
**RPC**是一种使程序能够在不同地址空间（通常在不同计算机上）调用彼此的方法的协议。</description><guid isPermaLink="true">https://jibinghu.github.io/post/C%2B%2B-zhong-jian-jian-jie-shao.html</guid><pubDate>Tue, 18 Jun 2024 01:30:47 +0000</pubDate></item><item><title>大话 Transformer(零基础看懂论文)</title><link>https://jibinghu.github.io/post/da-hua-%20Transformer%28-ling-ji-chu-kan-dong-lun-wen-%29.html</link><description>&#13;
---&#13;
&#13;
###### 由于课程实验要求以及专业学习关系，之前学过Transformer但仅局限于会用，这次深入探讨一下Transformer以便为大模型推理加速打个基础。</description><guid isPermaLink="true">https://jibinghu.github.io/post/da-hua-%20Transformer%28-ling-ji-chu-kan-dong-lun-wen-%29.html</guid><pubDate>Sat, 15 Jun 2024 06:20:07 +0000</pubDate></item><item><title>Brain Computer Interface</title><link>https://jibinghu.github.io/post/Brain%20Computer%20Interface.html</link><description>#### Technical terms learning:&#13;
&#13;
##### Brain-Computer Interface(BCI / 脑机接口):&#13;
&#13;
**定义：**&#13;
脑机接口是在大脑与外部设备之间创建信息通道，实现两者之间直接信息交互的新型交叉技术。</description><guid isPermaLink="true">https://jibinghu.github.io/post/Brain%20Computer%20Interface.html</guid><pubDate>Wed, 12 Jun 2024 13:36:26 +0000</pubDate></item><item><title>使用 ViT 训练 Cifar10 数据集</title><link>https://jibinghu.github.io/post/shi-yong-%20ViT%20-xun-lian-%20Cifar10%20-shu-ju-ji.html</link><description>#### 使用 ViT 训练 Cifar10 数据集&#13;
&#13;
**主要用来记录学习 ViT 中的问题帖子**&#13;
&#13;
---&#13;
&#13;
`nn.LayerNorm` 是 PyTorch 中的一个标准化层，它在神经网络中用于对输入数据进行层归一化。</description><guid isPermaLink="true">https://jibinghu.github.io/post/shi-yong-%20ViT%20-xun-lian-%20Cifar10%20-shu-ju-ji.html</guid><pubDate>Wed, 12 Jun 2024 10:27:08 +0000</pubDate></item><item><title>CUDA 矩阵乘优化分析</title><link>https://jibinghu.github.io/post/CUDA%20-ju-zhen-cheng-you-hua-fen-xi.html</link><description>#### 通过Shared Memory加速矩阵乘(Double等类型)分析&#13;
---&#13;
- [64位数据矩阵乘优化访存分析](#sector_1)&#13;
- [矩阵乘法的 CUDA 优化](#sector_2)&#13;
---&#13;
&#13;
#### 64位数据矩阵乘优化访存分析 {#sector_1}&#13;
&#13;
通过分析下面的代码，回答对应的两个问题(答案在文章结尾给出)。</description><guid isPermaLink="true">https://jibinghu.github.io/post/CUDA%20-ju-zhen-cheng-you-hua-fen-xi.html</guid><pubDate>Mon, 10 Jun 2024 12:45:09 +0000</pubDate></item><item><title>CUDA 线程布局以及内存层次</title><link>https://jibinghu.github.io/post/CUDA%20-xian-cheng-bu-ju-yi-ji-nei-cun-ceng-ci.html</link><description>### CUDA线程布局和内存层次&#13;
&#13;
&gt; [!CAUTION]&#13;
&gt; TODO :  CUDA 中 CUDA Core 硬件结构(SM/SP等)与软件层面布局对应关系及介绍&#13;
&#13;
**CUDA线程布局：**&#13;
&#13;
&lt;img src='https://img2024.cnblogs.com/blog/3358182/202405/3358182-20240514171810593-659841696.png' weight='300' height='200'&gt;&#13;
&#13;
如图所示，CUDA线程布局分为三层：网格(Grid),线程块(Block)以及线程(thread)&#13;
&#13;
&gt; [!IMPORTANT]&#13;
&gt; 在计算机中，内存的访问是一维的，线程的访问实质上也是一维的。</description><guid isPermaLink="true">https://jibinghu.github.io/post/CUDA%20-xian-cheng-bu-ju-yi-ji-nei-cun-ceng-ci.html</guid><pubDate>Wed, 05 Jun 2024 07:57:05 +0000</pubDate></item><item><title>Tensor core 详解</title><link>https://jibinghu.github.io/post/Tensor%20core%20-xiang-jie.html</link><description>## Tensor core 详解&#13;
&#13;
---&#13;
&#13;
#### Tensor Core剖析&#13;
&#13;
&gt; 在 NVIDIA 的通用 GPU 架构中，存在三种主要的核心类型：CUDA Core、Tensor Core 以及 RT Core。</description><guid isPermaLink="true">https://jibinghu.github.io/post/Tensor%20core%20-xiang-jie.html</guid><pubDate>Tue, 04 Jun 2024 13:52:36 +0000</pubDate></item><item><title>Java+微信小程序_Web介绍</title><link>https://jibinghu.github.io/post/Java%2B-wei-xin-xiao-cheng-xu-_Web-jie-shao.html</link><description>&gt; 前言：由于课程需要，简单地对 Java 相关框架以及Java Web相关知识做简单地学习，以备他用。</description><guid isPermaLink="true">https://jibinghu.github.io/post/Java%2B-wei-xin-xiao-cheng-xu-_Web-jie-shao.html</guid><pubDate>Mon, 03 Jun 2024 14:40:27 +0000</pubDate></item><item><title>从矩阵转置看共享内存(CUDA)</title><link>https://jibinghu.github.io/post/cong-ju-zhen-zhuan-zhi-kan-gong-xiang-nei-cun-%28CUDA%29.html</link><description>### 从矩阵转置看共享内存(CUDA的使用：Bank Conflict与Memory Coalesce)&#13;
---&#13;
- [矩阵转置的几种方法：](#sector_1)&#13;
  - [矩阵转置朴素实现：](#sector_1)&#13;
  - [利用共享内存合并访存：](#sector_2)&#13;
  - [利用 padding 解决 bank conflict：](#sector_3)&#13;
  - [增加每个线程的处理元素个数：](#sector_4)&#13;
  - [向量化存取：](#sector_5)&#13;
- [矩阵转置综合应用：](#chapter_2)&#13;
  - [Float数据类型转置：](#float)&#13;
  - [Double数据类型转置：](#double)&#13;
---&#13;
&gt; 矩阵转置是一种基础的矩阵操作, 即将二维矩阵的行列进行反转，本文主要围绕行主序的二维单精度矩阵的转置考虑相关的优化。</description><guid isPermaLink="true">https://jibinghu.github.io/post/cong-ju-zhen-zhuan-zhi-kan-gong-xiang-nei-cun-%28CUDA%29.html</guid><pubDate>Mon, 03 Jun 2024 03:41:48 +0000</pubDate></item><item><title>PaperReading_ConvStencil</title><link>https://jibinghu.github.io/post/PaperReading_ConvStencil.html</link><description>##### *PAPER READING*&#13;
&#13;
**@address: https://dl.acm.org/doi/10.1145/3627535.3638476**&#13;
**@github: https://github.com/microsoft/ConvStencil**&#13;
&#13;
### ConvStencil: Transform Stencil Computation to Matrix Multiplication on Tensor Cores&#13;
&#13;
##### 关键词：&#13;
    模版计算，卷积，张量核，矩阵乘&#13;
&#13;
##### 摘要：&#13;
&#13;
文章提出了ConvStencil，通过有效地将stencil模版计算转化为在张量核Tensor Core上的矩阵计算来实现。</description><guid isPermaLink="true">https://jibinghu.github.io/post/PaperReading_ConvStencil.html</guid><pubDate>Wed, 29 May 2024 11:24:12 +0000</pubDate></item><item><title>记录侯战森的罪证！</title><link>https://jibinghu.github.io/post/ji-lu-hou-zhan-sen-de-zui-zheng-%EF%BC%81.html</link><description>#### **天地可证**，侯战森是个大傻逼&#13;
&#13;
&lt;img src='https://img2024.cnblogs.com/blog/3358182/202405/3358182-20240528232629437-1616844405.jpg'&gt;。</description><guid isPermaLink="true">https://jibinghu.github.io/post/ji-lu-hou-zhan-sen-de-zui-zheng-%EF%BC%81.html</guid><pubDate>Tue, 28 May 2024 15:27:34 +0000</pubDate></item><item><title>new </title><link>https://jibinghu.github.io/post/new%20.html</link><description>first。</description><guid isPermaLink="true">https://jibinghu.github.io/post/new%20.html</guid><pubDate>Tue, 28 May 2024 10:09:39 +0000</pubDate></item></channel></rss>